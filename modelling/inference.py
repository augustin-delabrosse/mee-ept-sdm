"""
All docstrings and comments were generated by Claude Sonnet 4.
"""

from tqdm import tqdm
import numpy as np
import rasterio
from rasterio.enums import Resampling
import tensorflow as tf
import cv2
import os
import pickle

from config import *
from image_preprocessing import patch_minmaxnormalisation

class InsectProbabilityMapper:
    """
    Class to map insect occurrence probability from digital elevation models (DSM & DTM) and multispectral rasters and a trained model.
    """
    def __init__(self, ms_path, dsm_path, dtm_path, model_path, 
                 patch_size=128, target_resolution=0.32,
                 band_by_band_normalisation=True, reduce_to_5bands=True):
        """
        Initialize the mapper with raster paths, model, and processing options.
        Args:
            ms_path, dsm_path, dtm_path (str): paths to input rasters.
            model_path (str): path to the trained Keras model.
            patch_size (int): side of the square patch to sample. Should the same as the one used to train the model.
            target_resolution (float): desired pixel resolution (e.g., in meters). Should the same as the one used to train the model.
            band_by_band_normalisation (bool): normalize each channel separately. Should the same as the one used to train the model.
            reduce_to_5bands (bool): reduce multispectral raster to five bands. Should the same as the one used to train the model.
        """
        self.patch_size = patch_size
        self.pad = patch_size // 2
        self.band_by_band_normalisation = band_by_band_normalisation
        self.reduce_to_5bands = reduce_to_5bands
        self.target_resolution = target_resolution

        # Open all source rasters (multispectral, DSM, DTM)
        self.ms_src = rasterio.open(ms_path)
        self.dsm_src = rasterio.open(dsm_path)
        self.dtm_src = rasterio.open(dtm_path)

        # Find the intersection area of all rasters (to avoid missing data and ensure alignment)
        intersection_window, out_transform, out_shape = self.compute_intersection_window_and_shape()

        # Read, crop, and resample all rasters to the intersection grid and target resolution
        self.ms_resampled, self.dsm_resampled, self.dtm_resampled, self.meta = self.read_and_resample_to_intersection(
            intersection_window, out_transform, out_shape
        )

        # Load the trained TensorFlow model for prediction
        self.model = tf.keras.models.load_model(model_path)

    def compute_intersection_window_and_shape(self):
        """
        Compute the common bounding box (overlap) and output grid for all rasters.
        Returns:
            intersection_window (tuple): bounding box of overlap in (left, bottom, right, top).
            out_transform (Affine): affine transform for the output grid.
            out_shape (tuple): (height, width) of the output grid.
        """
        # Get bounding boxes for each raster (all in same CRS)
        ms_bounds = self.ms_src.bounds
        dsm_bounds = self.dsm_src.bounds
        dtm_bounds = self.dtm_src.bounds

        # Calculate intersection (overlapping region)
        left = max(ms_bounds.left, dsm_bounds.left, dtm_bounds.left)
        bottom = max(ms_bounds.bottom, dsm_bounds.bottom, dtm_bounds.bottom)
        right = min(ms_bounds.right, dsm_bounds.right, dtm_bounds.right)
        top = min(ms_bounds.top, dsm_bounds.top, dtm_bounds.top)

        # Check if there is a valid intersection
        if left >= right or bottom >= top:
            raise ValueError("No overlapping area between the rasters!")

        # Calculate output width and height at the desired resolution
        width = int(np.ceil((right - left) / self.target_resolution))
        height = int(np.ceil((top - bottom) / self.target_resolution))
        # Affine transform to map pixel coordinates to spatial coordinates
        out_transform = rasterio.transform.from_origin(left, top, self.target_resolution, self.target_resolution)
        intersection_window = (left, bottom, right, top)
        out_shape = (height, width)
        return intersection_window, out_transform, out_shape

    def read_and_resample_to_intersection(self, intersection_window, out_transform, out_shape):
        """
        Crop and resample all rasters to the same grid, covering the intersection area at target resolution.
        Returns:
            ms, dsm, dtm (RasterWrapper): objects with .image attribute containing the array data.
            meta (dict): updated raster metadata for output.
        """
        # Helper function to read and resample a raster to the output grid
        def read_raster(src, count=None):
            from rasterio.vrt import WarpedVRT
            vrt_options = {
                "resampling": Resampling.bilinear,
                "crs": src.crs,
                "transform": out_transform,
                "width": out_shape[1],
                "height": out_shape[0]
            }
            with WarpedVRT(src, **vrt_options) as vrt:
                if count is None:
                    arr = vrt.read(out_shape=out_shape)
                else:
                    arr = vrt.read(list(range(1, count+1)), out_shape=out_shape)
            return arr

        # Read the multispectral image (all bands)
        ms_resampled = read_raster(self.ms_src, count=self.ms_src.count) # (bands, H, W)
        # Optionally reduce to 5 bands (e.g., blue, green, red, red-edge, NIR)
        if self.reduce_to_5bands and ms_resampled.shape[0] >= 10:
            ms_resampled = ms_resampled[[1,3,5,7,9], :, :]
        # Read DSM and DTM as single-band rasters
        dsm_resampled = read_raster(self.dsm_src)[0]
        dtm_resampled = read_raster(self.dtm_src)[0]

        # Update the raster metadata (for saving predictions later)
        meta = self.ms_src.meta.copy()
        meta.update({
            "width": out_shape[1],
            "height": out_shape[0],
            "transform": out_transform
        })

        # Wrap arrays in simple objects for compatibility
        class RasterWrapper:
            def __init__(self, image):
                self.image = image
            def shape(self):
                return self.image.shape

        ms = RasterWrapper(ms_resampled)
        dsm = RasterWrapper(dsm_resampled)
        dtm = RasterWrapper(dtm_resampled)
        return ms, dsm, dtm, meta

    def get_valid_mask(self):
        """
        Returns a boolean mask of pixels where all rasters have valid (non-nodata) data.
        Returns:
            valid_mask (np.ndarray): shape (H, W), True where all rasters have valid data.
        """
        # Check where multispectral is not nodata in all bands
        ms_mask = np.all(self.ms_resampled.image != self.ms_src.nodata, axis=0)
        # Check DSM/DTM for NaNs
        dsm_mask = ~np.isnan(self.dsm_resampled.image)
        dtm_mask = ~np.isnan(self.dtm_resampled.image)
        valid_mask = ms_mask & dsm_mask & dtm_mask
        return valid_mask

    def preprocess_patch(self, ms_patch, dsm_patch, dtm_patch):
        """
        Prepare a patch for model prediction: fill missing values, clip, normalize, resize, and stack all layers.
        Args:
            ms_patch, dsm_patch, dtm_patch (np.ndarray): arrays of the patch.
        Returns:
            patch (np.ndarray): shape (patch_size, patch_size, n_bands_total).
        """
        # Replace NaNs with a consistent value for each layer
        ms_patch = np.nan_to_num(ms_patch, nan=-32767.0)
        dsm_patch = np.nan_to_num(dsm_patch, nan=-32767.0)
        dtm_patch = np.nan_to_num(dtm_patch, nan=-32767.0)

        # Clip negative values (should be > 0 for reflectance/height)
        ms_patch = ms_patch.clip(min=0)
        dsm_patch = dsm_patch.clip(min=0)
        dtm_patch = dtm_patch.clip(min=0)

        # Normalize patches (band by band for multispectral, DSM, DTM)
        ms_patch = patch_minmaxnormalisation(ms_patch, self.band_by_band_normalisation)
        dsm_patch = patch_minmaxnormalisation(dsm_patch, self.band_by_band_normalisation)
        dtm_patch = patch_minmaxnormalisation(dtm_patch, self.band_by_band_normalisation)

        # Resize patches if not already correct size
        if ms_patch.shape[0] != self.patch_size or ms_patch.shape[1] != self.patch_size:
            ms_patch = cv2.resize(ms_patch, (self.patch_size, self.patch_size), interpolation=cv2.INTER_LINEAR)
            dsm_patch = cv2.resize(dsm_patch, (self.patch_size, self.patch_size), interpolation=cv2.INTER_LINEAR)
            dtm_patch = cv2.resize(dtm_patch, (self.patch_size, self.patch_size), interpolation=cv2.INTER_LINEAR)

        # Stack channels into a single array (multispectral + DSM + DTM)
        dsm_patch = np.expand_dims(dsm_patch, axis=-1)
        dtm_patch = np.expand_dims(dtm_patch, axis=-1)
        patch = np.concatenate([ms_patch, dsm_patch, dtm_patch], axis=-1)
        return patch.astype(np.float32)

    def predict_map(self, batch_size=1024, checkpoint_path=None, checkpoint_interval=50000):
        """
        Predict the insect probability map over the entire raster extent using the trained model.

        Args:
            batch_size (int): Number of patches to process in parallel.
            checkpoint_path (str): Path for saving progress checkpoints, for large predictions.
            checkpoint_interval (int): Number of pixels between checkpoints.

        Returns:
            prob_map (np.ndarray): Probability map of shape (H, W).
        """
        ms = self.ms_resampled.image
        dsm = self.dsm_resampled.image
        dtm = self.dtm_resampled.image
        H, W = ms.shape[1], ms.shape[2]
        valid_mask = self.get_valid_mask()
        prob_map = np.full((H, W), np.nan, dtype=np.float32)
        pad = self.patch_size // 2

        # Pad all arrays to handle edges (patches at the border)
        ms_pad = np.pad(ms, ((0,0), (pad, pad), (pad, pad)), mode="edge")
        dsm_pad = np.pad(dsm, ((pad, pad), (pad, pad)), mode="edge")
        dtm_pad = np.pad(dtm, ((pad, pad), (pad, pad)), mode="edge")

        # List all valid positions for prediction
        positions = np.argwhere(valid_mask)
        X_batch = []
        batch_indices = []

        # If needed, resume from a saved checkpoint
        start_idx = 0
        if checkpoint_path is not None and os.path.exists(checkpoint_path):
            with open(checkpoint_path, "rb") as f:
                checkpoint = pickle.load(f)
            prob_map = checkpoint["prob_map"]
            start_idx = checkpoint["last_idx"] + 1
            print(f"Resuming prediction from pixel {start_idx}")

        # Main prediction loop: iterate through all valid pixel positions
        for idx in tqdm(range(start_idx, len(positions))):
            row, col = positions[idx]
            # Extract the patch for this pixel
            ms_patch = np.stack([
                ms_pad[b, row:row+self.patch_size, col:col+self.patch_size]
                for b in range(ms.shape[0])
            ], axis=-1)
            dsm_patch = dsm_pad[row:row+self.patch_size, col:col+self.patch_size]
            dtm_patch = dtm_pad[row:row+self.patch_size, col:col+self.patch_size]
            patch = self.preprocess_patch(ms_patch, dsm_patch, dtm_patch)
            X_batch.append(patch)
            batch_indices.append((row, col))

            # When batch is ready, predict probabilities and write to map
            if len(X_batch) == batch_size or idx == len(positions) - 1:
                X_arr = np.stack(X_batch, axis=0)
                preds = self.model.predict(X_arr, verbose=0)
                preds = preds.squeeze()
                for (r, c), prob in zip(batch_indices, preds):
                    prob_map[r, c] = prob
                X_batch = []
                batch_indices = []

            # Periodically save a checkpoint to recover from interruption
            if checkpoint_path is not None and (idx+1) % checkpoint_interval == 0:
                with open(checkpoint_path, "wb") as f:
                    pickle.dump({"prob_map": prob_map, "last_idx": idx}, f)

        # Final checkpoint save
        if checkpoint_path is not None:
            with open(checkpoint_path, "wb") as f:
                pickle.dump({"prob_map": prob_map, "last_idx": idx}, f)
            print(f"Final checkpoint saved at pixel {idx}")

        return prob_map

    def save_probability_map(self, prob_map, out_path):
        """
        Save the probability map as a GeoTIFF raster.

        Args:
            prob_map (np.ndarray): The probability map to save.
            out_path (str): Path for the output raster.
        """
        profile = self.meta.copy()
        profile.update(count=1, dtype='float32', nodata=np.nan)
        with rasterio.open(out_path, 'w', **profile) as dst:
            dst.write(prob_map, 1)

    def close(self):
        """Closes all open raster files."""
        self.ms_src.close()
        self.dsm_src.close()
        self.dtm_src.close()